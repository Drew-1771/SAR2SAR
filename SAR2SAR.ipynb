{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a94OoNwSB4K8"
   },
   "source": [
    "# SAR2SAR: a self-supervised despeckling algorithm for SAR images\n",
    "## Emanuele Dalsasso, Loïc Denis, Florence Tupin\n",
    "\n",
    "Please note that the training set is only composed of **GRD** SAR images, thus this testing code is specific to this data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V7SJyBmKrSIH",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Resources\n",
    "- [Paper (ArXiv)](https://arxiv.org/abs/2006.15037)\n",
    "\n",
    "To cite the article:\n",
    "\n",
    "    @article{dalsasso2020sar2sar,\n",
    "        title={{SAR2SAR}: a self-supervised despeckling algorithm for {SAR} images},\n",
    "        author={Emanuele Dalsasso and Loïc Denis and Florence Tupin},\n",
    "        journal={arXiv preprint arXiv:2006.15037},\n",
    "        year={2020}\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rBSypL94C9L3"
   },
   "source": [
    "## 1. Install required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fn6fXbssdjm4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vJfhq_QbGvkg"
   },
   "source": [
    "## 2. Set up the data environment\n",
    "The model.py contains the run_model function. Here is the docstring for the run_model function:\n",
    "    \n",
    "    Runs the despeckling algorithm\n",
    "\n",
    "    Arguments:\n",
    "        input_dir: Path to a directory containing the files to be despeckled. Files need to be in .npy\n",
    "                   format\n",
    "        save_dir: Path to a directory where the files will be saved\n",
    "        checkpoint_dir: Path to a directory containing the tensorflow checkpoints, if left as None, the\n",
    "                        despeckling algorithm will use the grd_checkpoint directory\n",
    "        stride: U-Net is scanned over the image with a default stride of 64 pixels when the image dimension\n",
    "                exceeds 256. This parameter modifies the default stride in pixels. Lower pixel count = higher quality\n",
    "                results, at the cost of higher runtime\n",
    "        store_noisy: Whether to store the \"noisy\" or input in the save_dir. Default is False\n",
    "        generate_png: Whether to generate PNG of the outputs in the save_dir. Default is True\n",
    "        debug: Whether to generate print statements at runtime that communicate what is going on\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "**You will need to set the input_dir and save_dir filepaths.** Here is an example of what that could look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# current folder this file is in\n",
    "current_dir = Path(os.getcwd())\n",
    "\n",
    "# set the path of the input and save directories\n",
    "example_input_dir = str(current_dir / \"src\" / \"test_data\" / \"example_test_data\")\n",
    "example_save_dir = str(current_dir / \"example_output\")\n",
    "\n",
    "# set the path of your own input and save directory\n",
    "input_dir = str(current_dir / \"my_data\" / \"input\")\n",
    "save_dir = str(current_dir / \"my_data\" / \"results\")\n",
    "\n",
    "print(f\"Input directory set to: {input_dir}\")\n",
    "print(f\"Save directory set to: {save_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting .tif to .npy\n",
    "If your data is in .tif form, and you would like to run this algorithm, you will need to convert it to .npy (and subsequently convert it back to tif when it is done, though this can be more complicated based on your input and how you want your results). An easy way to do that is with the rasterio python library and this function, which converts all single band .tif and .TIF files in the input_dir directory to .npy files. Multi-band rasters are more complicated, and should be split up into single band rasters on your own terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "\n",
    "# file extensions\n",
    "tif_extensions = [\".tif\", \".TIF\"]\n",
    "npy_extensions = [\".npy\"]\n",
    "\n",
    "def tifToNpy(input_dir: str, extensions: list=[\".tif\", \".TIF\"]) -> None:\n",
    "    \"\"\"\n",
    "    Converts the files in the input_dir directory with the given extensions to .npy files\n",
    "\n",
    "    Arguments:\n",
    "        input_dir: Path to the input directory\n",
    "        extensions: list of valid extensions for files\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    input_dir = Path(input_dir)\n",
    "    # get each .tif/.TIF file in the input_dir directory\n",
    "    for file in input_dir.iterdir():\n",
    "        if not file.is_dir() and file.suffix in extensions:\n",
    "            # open the file and read the data\n",
    "            with rasterio.open(str(file)) as src:\n",
    "                data = src.read()\n",
    "                # save as a .npy\n",
    "                if data.shape[0] == 1:\n",
    "                    # if there is only one band\n",
    "                    path_to_output = file.with_suffix(\".npy\")\n",
    "                    np.save(path_to_output, np.squeeze(data))\n",
    "                else:\n",
    "                    # if there are multiple bands, this introduces many complications when trying to re-combine later. Everyone's setup and needs\n",
    "                    # are different so you will have to write your own code to handle these cases. Here is an example of what it could look like\n",
    "                    \"\"\"\n",
    "                    for i in range(data.shape[0]):\n",
    "                        filename = str(Path(file.name).with_suffix(\"\"))\n",
    "                        path_to_output = file.with_name(filename + f\"_B{i}\").with_suffix(\n",
    "                            \".npy\"\n",
    "                        )\n",
    "                        np.save(path_to_output, np.squeeze(data[i]))\n",
    "                    \"\"\"\n",
    "                    raise ValueError(\"Multiple bands, please split up into single band rasters for easier processing\")\n",
    "\n",
    "# convert tif files in the input directory to .npy\n",
    "tifToNpy(input_dir, tif_extensions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mZTikzYaR0zh"
   },
   "source": [
    "## 3. Run the example model\n",
    "Run the example model to make sure that everything has been installed correctly and is ready to run. **This code was originally written for Tensorflow V1, so the tensorflow library will throw a lot of warnings.**\n",
    "When the model is done, you should see a folder named example_output with the results\n",
    "\n",
    "***The model will print this line when it has finished:***\n",
    "\n",
    "[!!!] Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JdSva30cNp75"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.compat.v1.reset_default_graph()\n",
    "from src.model import run_model\n",
    "\n",
    "run_model(example_input_dir, example_save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run the model on your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "run_model(input_dir, save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Convert the data back to .tif\n",
    "If your data was in .tif form, you probably want your results to be in .tif form too. Converting back can be more complicated because of the tif's associated metadata. Here is a simple approach that uses the original .tif as a mirror for the metadata of the original file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def npyToTif(processed_npy_file: str, metadata_mirror: str) -> None:\n",
    "    \"\"\"\n",
    "    Converts the processed .npy file back to .tif using the metadata from the metadata mirror tif,\n",
    "    the original .tif before processing\n",
    "\n",
    "    Arguments:\n",
    "        processed_npy_file: Path to the processed .npy file\n",
    "        metadata_mirror: Path to the original .tif file this .npy file as generated from. The metadata mirror\n",
    "                         allows rasterio to write the metadata of the original .tif onto the despeckled result.\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # open the orignal tif to get its metadata\n",
    "    with rasterio.open(metadata_mirror) as src:\n",
    "        # rename the file\n",
    "        filename = str(Path(processed_npy_file).with_suffix(\"\").name)\n",
    "        path_to_output = Path(processed_npy_file).with_name(\"denoised_\" + filename).with_suffix(\".tif\")\n",
    "        # open the new denoised_ .tif and write the .npy w/ the mirror metadata\n",
    "        with rasterio.open(path_to_output, \"w\", **src.meta) as dst:\n",
    "            dst.write(np.stack([np.load(processed_npy_file)]))\n",
    "\n",
    "# get the original files and the despeckled results and search for matches on file name\n",
    "original_files, despeckled_files = [file for file in Path(input_dir).iterdir()  if not file.is_dir() and file.suffix in tif_extensions], [file for file in Path(save_dir).iterdir()  if not file.is_dir() and file.suffix in npy_extensions]\n",
    "for i in range(len(despeckled_files)):\n",
    "    for j in range(len(original_files)):\n",
    "        # if the file names are the same, convert .npy to .tif\n",
    "        if despeckled_files[i].with_suffix(\"\").name == original_files[j].with_suffix(\"\").name:\n",
    "            print(f\"Converting {despeckled_files[i].name} to tif with metadata mirror at {original_files[j].name} to {'denoised_' + original_files[j].name}\")\n",
    "            npyToTif(str(despeckled_files[i]), str(original_files[j]))\n",
    "                "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "SAR2SAR_GRD_test.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
